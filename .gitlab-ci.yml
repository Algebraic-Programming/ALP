# default settings based on standard Docker image for reproducible build:
# see https://github.com/Algebraic-Programming/ReproducibleBuilds
default:
  tags:
    - docker
  image: ${CI_REGISTRY}/${CI_PROJECT_PATH}/lpf-ubuntu-20.04-gcc

variables:
  EXTRA_TESTS_ENABLED:
    value: "no"
    options:
      - "yes"
      - "no"
    description: "Enable extra tests: build with debug symbols, performance tests"
  LPF_TESTS_ENABLED:
    value: "no"
    options:
      - "yes"
      - "no"
    description: "Enable LPF-based tests"
  MULTIPLE_COMPILERS_ENABLED:
    value: "no"
    options:
      - "yes"
      - "no"
    description: "Enable compilation using multiple compilers"
  SLURM_TESTS_ENABLED:
    value: "no"
    options:
      - "yes"
      - "no"
    description: "Enable test on the Slurm cluster"
  CI_SLURM_PARTITION:
    value: "Zen3"
    description: "Partition to use (if using Slurm)"
  CI_SLURM_NNODES:
    value: "1"
    description: "Number of nodes to request (if using Slurm)"
  CI_SLURM_NTASKS:
    value: "1"
    description: "Number of tasks to request (if using Slurm)"
  CI_SLURM_CPUS_PER_TASK:
    value: "64"
    description: "Number of CPUs per task (if using Slurm)"
  CI_SLURM_MEM_PER_NODE:
    value: "64G"
    description: "Memory per node (if using Slurm)"
  CI_SLURM_TIMELIMIT:
    value: "00-10:00:00" # 10 hours
    description: "Time limit for the job (if using Slurm)"
  SLURM_JOB_START_TIMEOUT_SECONDS:
    value: "3600" # 1 hour timeout to switch from PENDING to RUNNING
    description: "Allowed time for the job to switch from PENDING to RUNNING (if using Slurm)"
  SLURM_DATASETS_DIR_PATH:
    value: "/storage/datasets/graphs-and-sparse-matrices"
    description: "Path to the datasets directory (if using Slurm)"
  COVERAGE_ENABLED:
    value: "no"
    options:
      - "yes"
      - "no"
    description: "Execute coverage build and tests, then exports XML and HTML reports"
  GENERATE_COVERAGE_PAGES:
    value: "no"
    options:
      - "yes"
      - "no"
    description: "Generate coverage report for Gitlab Pages"

workflow:
  rules:
  # run all jobs if a commit is merged on master, develop or a version/rc branch
    - if: $CI_COMMIT_BRANCH == "master"
      variables:
        EXTRA_TESTS_ENABLED: "yes"
        LPF_TESTS_ENABLED: "yes"
        MULTIPLE_COMPILERS_ENABLED: "yes"
        COVERAGE_ENABLED: "yes"
    - if: $CI_COMMIT_BRANCH == "develop"
      variables:
        EXTRA_TESTS_ENABLED: "yes"
        LPF_TESTS_ENABLED: "yes"
        MULTIPLE_COMPILERS_ENABLED: "yes"
        COVERAGE_ENABLED: "yes"
        GENERATE_COVERAGE_PAGES: "yes"
    - if: $CI_COMMIT_BRANCH =~ /^v.*-rc.*$/
      variables:
        EXTRA_TESTS_ENABLED: "yes"
        LPF_TESTS_ENABLED: "yes"
        MULTIPLE_COMPILERS_ENABLED: "yes"
    # "manual" execution strategies are allowed to force run
    - if: $CI_PIPELINE_SOURCE != "merge_request_event" && $CI_PIPELINE_SOURCE != "push"
    # do not run pipeline if the merge request is draft (case insensitive) and execution was automatically invoked
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TITLE =~ /^draft:/i
      when: never
    # run if the pipeline comes from a merge request
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      variables:
        COVERAGE_ENABLED: "yes"
    # default: don't run


# factored out command to strip symbols from test binaries
.strip_symbols: &strip_symbols
  - strip -s $(find tests/unit/ -type f -executable -print)
    $(find tests/smoke/ -type f -executable -print)
    $(find tests/performance/ -type f -executable -print)

# Build / test / install on CentOS 8, only for main branches

#build_centos_8:
#  image: centos:8
#  rules:
#    - if: $EXTRA_TESTS_ENABLED == "yes"
#  before_script:
#    - yum -y update && yum -y groupinstall "Development Tools" && yum -y install make autoconf cmake numactl-devel
#  script:
#    - rm -rf build install && mkdir -p install build && cd ./build && ../bootstrap.sh --prefix=../install && make -j$(nproc) && make -j$(nproc) build_tests_all
#    - *strip_symbols
#  artifacts:
#    paths:
#      - build/
#    exclude:
#      - build/**/*.o
#      - build/**/*.o.d
#    expire_in: 2 hours


#build_debug_centos_8:
#  image: centos:8
#  before_script:
#    - yum -y update && yum -y groupinstall "Development Tools" && yum -y install make autoconf cmake numactl-devel
#  script:
#    - mkdir -p install build && cd ./build && ../bootstrap.sh --prefix=../install --debug-build && make -j$(nproc) && make -j$(nproc) build_tests_all
#  rules:
#    - if: $EXTRA_TESTS_ENABLED == "yes"


#test_centos_8_unit:
#  image: centos:8
#  needs: [build_centos_8]
#  rules:
#    - if: $EXTRA_TESTS_ENABLED == "yes"
#  before_script:
#    - yum -y update && yum -y groupinstall "Development Tools" && yum -y install make autoconf cmake numactl-devel
#  script:
#    - cd ./build && make -j$(nproc) tests_unit &> unittests.log
#    - ../tests/summarise.sh unittests.log


#test_centos_8_smoke:
#  image: centos:8
#  needs: [build_centos_8]
#  rules:
#    - if: $EXTRA_TESTS_ENABLED == "yes"
#  before_script:
#    - yum -y update && yum -y groupinstall "Development Tools" && yum -y install make autoconf cmake numactl-devel
#  script:
#    - cd ./build && make -j$(nproc) tests_smoke &> smoketests.log
#    - ../tests/summarise.sh smoketests.log


#test_centos_8_performance:
#  image: centos:8
#  needs: [build_centos_8]
#  rules:
#    - if: $EXTRA_TESTS_ENABLED == "yes"
#  before_script:
#    - yum -y update && yum -y groupinstall "Development Tools" && yum -y install make autoconf cmake numactl-devel
#  script:
#    - cd ./build &&  make -j$(nproc) tests_performance &> performancetests.log
#    - ../tests/summarise.sh performancetests.log tests/performance/output/benchmarks tests/performance/output/scaling


#test_centos_8_installation:
#  image: centos:8
#  needs: [build_centos_8]
#  rules:
#    - if: $EXTRA_TESTS_ENABLED == "yes"
#  before_script:
#    - yum -y update && yum -y groupinstall "Development Tools" && yum -y install make autoconf cmake numactl-devel
#  script:
#    - cd ./build && make -j$(nproc) install


# Main testing on Ubuntu, all branches

build_test:
  script:
    - mkdir -p install build && cd ./build && ../bootstrap.sh --prefix=../install --with-datasets=${ALP_DATASETS}
    - make -j$(nproc) && make -j$(nproc) build_tests_all
    - *strip_symbols
  artifacts:
    paths:
      - build/
    exclude:
      - build/**/*.o
      - build/**/*.o.d
      - build/**/CMakeFiles
      - build/**/*.dir
    expire_in: 2 hours


build_tests_build_type_debug_sym_debug:
  script:
    - mkdir -p install build && cd build && cmake -DCMAKE_INSTALL_PREFIX=../install -DCMAKE_CXX_FLAGS=-D_DEBUG
      -DCMAKE_C_FLAGS=-D_DEBUG -DCMAKE_BUILD_TYPE=Debug ../
    - make -j$(nproc) && make -j$(nproc) build_tests_all


build_tests_sym_debug:
  rules:
    - if: $EXTRA_TESTS_ENABLED == "yes"
  script:
    - mkdir -p install build && cd build && cmake -DCMAKE_INSTALL_PREFIX=../install -DCMAKE_CXX_FLAGS=-D_DEBUG
      -DCMAKE_C_FLAGS=-D_DEBUG -DLPF_INSTALL_PATH=${LPF_PATH} -DCMAKE_BUILD_TYPE=Release ../
    - make -j$(nproc) && make -j$(nproc) build_tests_all


# must specify CTEST_CATEGORY and CTEST_BACKEND to filter
.ctests_run:
  script:
    - cd build
    - cmake . # re-configure to update the available resources
    - |
      echo "CATEGORY: ${CTEST_CATEGORY}; BACKEND: ${CTEST_BACKEND}"
    - ${CMAKE_RECENT}/ctest -L "mode:${CTEST_CATEGORY}" -L "backend:${CTEST_BACKEND}" --output-junit ${CTEST_CATEGORY}.xml
      --output-on-failure || true
    - python3 ${CI_PROJECT_DIR}/tools/ctest-junit-parse.py --categories ${CTEST_CATEGORY} --xmls-dir $(pwd)
      --remove-successful-logs-from $(pwd)/tests
  artifacts:
    when: always
    name: "${CTEST_CATEGORY}_failed_tests"
    paths:
      - build/tests/${CTEST_CATEGORY}/output/
      - build/${CTEST_CATEGORY}.xml
    reports:
      junit: build/${CTEST_CATEGORY}.xml
    expire_in: 1 week


default_tests_matrix:
  needs: [build_test]
  variables:
    CTEST_BACKEND: ".*" # match all enabled backends
  parallel:
    matrix:
      - CTEST_CATEGORY: [unit, smoke]
  extends: .ctests_run


test_installation:
  needs: [build_test]
  script:
    - cd ./build && make -j$(nproc) install


build_test_build_type_debug:
  script:
    - mkdir -p install build && cd ./build && ../bootstrap.sh --prefix=../install --with-datasets=${ALP_DATASETS}
      --debug-build && make -j$(nproc) && make -j$(nproc) build_tests_all
    - *strip_symbols
  artifacts:
    paths:
      - build/
    exclude:
      - build/**/*.o
      - build/**/*.o.d
    expire_in: 2 hours


test_smoke_build_type_debug:
  needs: [build_test_build_type_debug]
  variables:
    CTEST_BACKEND: ".*" # match all enabled backends
    CTEST_CATEGORY: smoke
  extends: .ctests_run


test_installation_build_type_debug:
  needs: [build_test_build_type_debug]
  script:
    - cd ./build && make -j$(nproc) install


gitleaks:
  image:
    name: "zricethezav/gitleaks:v8.0.6"
    entrypoint: [""]
  script: gitleaks detect -v --source .


## Jobs running on Slurm cluster

# factored out command to download the datasets, cmake, and build in non-debug mode
.setup_and_build_ndebug_slurm: &setup_and_build_ndebug_slurm
  - mkdir -p install build && cd ./build
  - ../bootstrap.sh --prefix=../install --with-datasets=${SLURM_DATASETS_DIR_PATH} --no-hyperdags
  - make -j$(nproc)

tests_performance_slurm:
  rules:
    - if: $SLURM_TESTS_ENABLED == "yes"
  tags:
    - slurm
  script:
    - *setup_and_build_ndebug_slurm
    - make -j$(nproc) performancetests |& tee performancetests.log
    - ../tests/summarise.sh performancetests.log tests/performance/output/benchmarks tests/performance/output/scaling
  artifacts:
    paths: [ build/*.log ]
    expire_in: 1 month


## Additional tests specific to main branches only

tests_performance:
  rules:
    - if: $EXTRA_TESTS_ENABLED == "yes"
  needs: [build_test]
  variables:
    CTEST_BACKEND: ".*" # match all enabled backends
    CTEST_CATEGORY: "performance"
  extends: .ctests_run


tests_unit_build_type_debug:
  rules:
    - if: $EXTRA_TESTS_ENABLED == "yes"
  needs: [build_test_build_type_debug]
  variables:
    CTEST_BACKEND: ".*" # match all enabled backends
    CTEST_CATEGORY: "unit"
  extends: .ctests_run


## Additional tests for LPF (on main branches only)

build_test_lpf:
  rules:
    - if: $LPF_TESTS_ENABLED == "yes"
  script:
# build only LPF-related tests
    - mkdir -p install build && cd ./build && ../bootstrap.sh --with-lpf=${LPF_PATH} --no-nonblocking --no-reference
      --no-hyperdags --prefix=../install --with-datasets=${ALP_DATASETS}
    - make -j$(nproc) && make -j$(nproc) build_tests_all
    - *strip_symbols
  artifacts:
    paths:
      - build/
    exclude:
      - build/**/*.o
      - build/**/*.o.d
      - build/**/CMakeFiles
      - build/**/*.dir
    expire_in: 2 hours

# common sections for  LPF unit tests: must specify CTEST_CATEGORY
.tests_category_lpf:
  needs: [build_test_lpf]
  variables:
    CTEST_BACKEND: "bsp1d|hybrid" # match bsp1d and hybrid backends
  extends: .ctests_run

# this job triggers in internal CI, where LPF tests run better on runners
# with a given tag $LPF_PREFERRED_RUNNERS_TAG
tests_unit_lpf_preferred:
  rules:
    - if: $LPF_TESTS_ENABLED == "yes" && $LPF_PREFERRED_RUNNERS == "yes"
  tags:
    - docker
    - $LPF_PREFERRED_RUNNERS_TAG
  variables:
    CTEST_CATEGORY: "unit"
  extends: .tests_category_lpf


# if runners with a specific tag are not present, run this job
# attention: it may timeout
tests_unit_lpf_generic:
  rules:
    - if: $LPF_TESTS_ENABLED == "yes" && $LPF_PREFERRED_RUNNERS != "yes"
  variables:
    CTEST_CATEGORY: "unit"
  extends: .tests_category_lpf


tests_smoke_lpf:
  rules:
    - if: $LPF_TESTS_ENABLED == "yes"
  needs: [build_test_lpf]
  variables:
    CTEST_CATEGORY: "smoke"
  extends: .tests_category_lpf


test_installation_lpf:
  rules:
    - if: $LPF_TESTS_ENABLED == "yes"
  needs: [build_test_lpf]
  script:
    - cd ./build && make -j$(nproc) install


## Additional jobs to build againt multiple compilers (on main branches only)

build_test_gcc_versions:
  rules:
    - if: $MULTIPLE_COMPILERS_ENABLED == "yes"
  image: ${CI_REGISTRY}/${CI_PROJECT_PATH}/lpf-ubuntu-22.04-gcc-clang
  parallel:
      matrix:
        - CXX_COMPILER: g++
          CC_COMPILER: gcc
          VER: [9,10,11,12]
        # - CXX_COMPILER: clang++
        #   CC_COMPILER: clang
        #   VER: [11,12,13,14]
  script:
    - mkdir -p install build && cd ./build &&
      CXX=${CXX_COMPILER}-${VER} CC=${CC_COMPILER}-${VER} ../bootstrap.sh
      --prefix=../install --with-datasets=${ALP_DATASETS}
      --with-lpf=${LPF_BASE_PATH}/build_mpich_${CC_COMPILER}_${VER}/install &&
      make -j$(nproc) build_tests_all


# Coverage build + tests for each backend

coverage_matrix:
  rules:
    - if: $COVERAGE_ENABLED == "yes" || $GENERATE_COVERAGE_PAGES == "yes"
  needs: [build_test]
  parallel:
    matrix:
      # ________: HYPERDAGS  REFERENCE  REFERENCE_OMP  NONBLOCKING
      - BACKENDS: OFF        ON         OFF            OFF          # REFERENCE
      - BACKENDS: OFF        OFF        ON             OFF          # REFERENCE_OMP
      - BACKENDS: ON         OFF        OFF            OFF          # HYPERDAGS (reference_omp)
      - BACKENDS: OFF        OFF        OFF            ON           # NONBLOCKING
  script:
    - read -a backends_array <<< "$BACKENDS"
    - echo "-- HYPERDAGS=${backends_array[0]}"
    - echo "-- REFERENCE=${backends_array[1]}"
    - echo "-- REFERENCE_OMP=${backends_array[2]}"
    - echo "-- NONBLOCKING=${backends_array[3]}"

    - rm -rf build install && mkdir -p install build && cd build
    - cmake -DCMAKE_INSTALL_PREFIX='../install'
      -DCMAKE_BUILD_TYPE=Coverage
      -DDATASETS_DIR=${ALP_DATASETS}
      -DWITH_HYPERDAGS_BACKEND=${backends_array[0]}
      -DWITH_REFERENCE_BACKEND=${backends_array[1]}
      -DWITH_OMP_BACKEND=${backends_array[2]}
      -DWITH_NONBLOCKING_BACKEND=${backends_array[3]} ..
    - make -j$(nproc) build_tests_category_unit
    - ${CMAKE_RECENT}/ctest -L "mode:unit" --output-on-failure || true # ignore not run tests (failing ones are detected in standard jobs)
# for each job (i.e., each backend), generate a separate JSON to me merged later
# (gcovr merges only JSON files)
    - python3 -m gcovr --json
      --print-summary
      --exclude-directories "/usr/*"
      --root ${CI_PROJECT_DIR}
      --output ${CI_PROJECT_DIR}/COVERAGE_${CI_JOB_ID}.json
  artifacts:
    paths:
      - COVERAGE_${CI_JOB_ID}.json
    expire_in: 4 weeks


cobertura_coverage_report:
  rules:
    - if: $COVERAGE_ENABLED == "yes" || $GENERATE_COVERAGE_PAGES == "yes"
  needs: [coverage_matrix]
  script:
# merge JSON files from multiple backends into single Cobertura report for the CI
    - python3 -m gcovr --xml-pretty
      --add-tracefile "COVERAGE_*.json"
      --print-summary
      --root ${CI_PROJECT_DIR}
      --output coverage.xml
  coverage: /^\s*lines:\s*\d+.\d+\%/
  artifacts:
    name: ${CI_JOB_NAME}-${CI_COMMIT_REF_NAME}-${CI_COMMIT_SHA}
    expire_in: 4 weeks
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml


html_coverage_report:
  rules:
    - if: $COVERAGE_ENABLED == "yes" || $GENERATE_COVERAGE_PAGES == "yes"
  needs: [coverage_matrix]
  script:
    - mkdir -p public
# merge JSON files from multiple backends into single HTNL report for the CI
    - python3 -m gcovr --html-details
      --add-tracefile "COVERAGE_*.json"
      --print-summary
      --sort-percentage
      --html-title "Branch ${CI_COMMIT_BRANCH}, commit ${CI_COMMIT_SHA}"
      --root ${CI_PROJECT_DIR}
      --output public/index.html
  artifacts:
    expire_in: 4 weeks
    paths:
      - public


## GitLab Pages update job

pages:
  rules:
    - if: $GENERATE_COVERAGE_PAGES == "yes"
  needs: [html_coverage_report]
  script:
    - mkdir -p public
  artifacts:
    paths:
      - public
